{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import numpy as np\n",
    "from mnist import load_data\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training, validation, testing = load_data()\n",
    "train_x, train_y, test_x, test_y = training[0], training[1], testing[0], testing[1]\n",
    "train_y = utils.one_hot_encoding(train_y)\n",
    "test_y = utils.one_hot_encoding(test_y)\n",
    "\n",
    "class Network():\n",
    "    def __init__(self, layers, lr=0.0001, epochs=10):\n",
    "        self.n_layers = len(layers)\n",
    "        self.layers = layers\n",
    "        w1 = np.random.rand(784, layers[0])\n",
    "        w_last = np.random.rand(layers[len(layers)-1], 10)\n",
    "        self.weights = [np.random.rand(x, y) for x, y in zip(layers[:-1], layers[1:])]\n",
    "        self.weights.insert(0, w1)\n",
    "        self.weights.append(w_last)\n",
    "        self.weights = np.asarray(self.weights)\n",
    "        \n",
    "        self.biases = [np.random.rand(y) for x, y in zip(layers[:-1], layers[1:])]\n",
    "        b1 = np.random.rand(1, layers[0])\n",
    "        b_last = np.random.rand(1, 10)\n",
    "        self.biases.insert(0, b1)\n",
    "        self.biases.append(b_last)\n",
    "        self.biases = np.array(self.biases)\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        activations = []\n",
    "        z_vec = []\n",
    "        for w, b in zip (self.weights, self.biases):\n",
    "            z = np.dot(inputs, w) + b\n",
    "            inputs = utils.sigmoid(z)\n",
    "            z_vec.append(z)\n",
    "            activations.append(inputs)\n",
    "        return inputs, activations, z_vec\n",
    "    \n",
    "    def compute_loss(self, logits, labels, epsilon=np.finfo(float).eps):\n",
    "        return -np.sum(np.multiply(labels, np.log10(logits+epsilon)))/logits.shape[0]\n",
    "    \n",
    "    def get_gradients(self, logits, labels, activations):\n",
    "        w_last = self.weights[-1]\n",
    "        w_last_g = np.dot(activations[-2].T, (logits - labels))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Network([10, 20])\n",
    "predict, activations, z = model.feed_forward(train_x)\n",
    "model.get_gradients(logits=predict, labels=train_y, activations=activations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
